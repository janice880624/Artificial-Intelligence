{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "\n",
    "parameters = {}\n",
    "KERNEL_LINEAR = 1\n",
    "KERNEL_RBF = 2\n",
    "\n",
    "DATASET_LINEARLY_SEPARABLE = 1\n",
    "DATASET_CIRCULAR = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = np.loadtxt(\"iris.txt\")\n",
    "    iris_data = data[50:]\n",
    "    return iris_data \n",
    "\n",
    "def get_train_and_test(feature):\n",
    "    iris_data = get_data()\n",
    "\n",
    "    positive_data = iris_data[:50, feature]\n",
    "    positive_data = np.expand_dims(positive_data, axis=2)\n",
    "\n",
    "    negative_data = iris_data[50:, feature]\n",
    "    negative_data = np.expand_dims(negative_data, axis=2)\n",
    "\n",
    "    train_data_positive = positive_data[:25]\n",
    "    train_data_negative = negative_data[:25]\n",
    "\n",
    "    test_data_positive = positive_data[25:]\n",
    "    test_data_negative = negative_data[25:]\n",
    "\n",
    "    train_data = np.concatenate((train_data_positive, train_data_negative), axis=0)\n",
    "    test_data = np.concatenate((test_data_positive, test_data_negative), axis=0)\n",
    "\n",
    "    train_label = [1.0] * len(train_data_positive) + [-1.0] * len(train_data_negative)\n",
    "    test_label = [1.0] * len(test_data_positive) + [-1.0] * len(test_data_negative)\n",
    "\n",
    "    train_label_plot = ['positive'] * len(train_data_positive) + ['negative'] * len(train_data_negative)\n",
    "    test_label_plot = ['positive'] * len(test_data_positive) + ['negative'] * len(test_data_negative)\n",
    "\n",
    "    return(train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative)\n",
    "\n",
    "def get_test_and_train(feature):\n",
    "    iris_data = get_data()\n",
    "\n",
    "    positive_data = iris_data[:50, feature]\n",
    "    positive_data = np.expand_dims(positive_data, axis=2)\n",
    "\n",
    "    negative_data = iris_data[50:, feature]\n",
    "    negative_data = np.expand_dims(negative_data, axis=2)\n",
    "\n",
    "    train_data_positive = positive_data[25:]\n",
    "    train_data_negative = negative_data[25:]\n",
    "\n",
    "    test_data_positive = positive_data[:25]\n",
    "    test_data_negative = negative_data[:25]\n",
    "\n",
    "    train_data = np.concatenate((train_data_positive, train_data_negative), axis=0)\n",
    "    test_data = np.concatenate((test_data_positive, test_data_negative), axis=0)\n",
    "\n",
    "    train_label = [1.0] * len(train_data_positive) + [-1.0] * len(train_data_negative)\n",
    "    test_label = [1.0] * len(test_data_positive) + [-1.0] * len(test_data_negative)\n",
    "\n",
    "    train_label_plot = ['positive'] * len(train_data_positive) + ['negative'] * len(train_data_negative)\n",
    "    test_label_plot = ['positive'] * len(test_data_positive) + ['negative'] * len(test_data_negative)\n",
    "\n",
    "    return(train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data1(dataset):\n",
    "    feature = [2, 3]\n",
    "\n",
    "    train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative = get_train_and_test(feature)\n",
    "\n",
    "    train_data = np.squeeze(train_data, axis=(2,))\n",
    "    train_label = np.array(train_label)\n",
    "\n",
    "    X = train_data\n",
    "    y = train_label \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def generate_data2(dataset):\n",
    "    feature = [2, 3]\n",
    "\n",
    "    train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative = get_test_and_train(feature)\n",
    "\n",
    "    train_data = np.squeeze(train_data, axis=(2,))\n",
    "    train_label = np.array(train_label)\n",
    "\n",
    "    X = train_data\n",
    "    y = train_label \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(X, Y, kernel_type, gamma=200):\n",
    "    K = np.zeros((X.shape[0], Y.shape[0]))\n",
    "    \n",
    "    if kernel_type == KERNEL_LINEAR:\n",
    "        for i, x in enumerate(X):\n",
    "            for j, y in enumerate(Y):\n",
    "                K[i, j] = np.dot(x.T, y)\n",
    "                \n",
    "    elif kernel_type == KERNEL_RBF:\n",
    "        for i, x in enumerate(X):\n",
    "            for j, y in enumerate(Y):\n",
    "                K[i, j] = np.exp(-gamma * np.linalg.norm(x - y) ** 2)\n",
    "        \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm1(kernel):\n",
    "    C = 10\n",
    "\n",
    "    feature = [2, 3]\n",
    "    train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative = get_train_and_test(feature)\n",
    "\n",
    "    train_data = np.squeeze(train_data, axis=(2,))\n",
    "    train_label = np.array(train_label)\n",
    "\n",
    "    n, k = train_data.shape\n",
    "    \n",
    "    y_matrix = y.reshape(1, -1)\n",
    "    H = np.dot(y_matrix.T, y_matrix) * gram_matrix(X, X, kernel)\n",
    "    P = cvxopt_matrix(H)\n",
    "    q = cvxopt_matrix(-np.ones((n, 1)))\n",
    "    G = cvxopt_matrix(np.vstack((-np.eye((n)), np.eye(n))))\n",
    "    h = cvxopt_matrix(np.vstack((np.zeros((n,1)), np.ones((n,1)) * C)))\n",
    "    A = cvxopt_matrix(y_matrix)\n",
    "    b = cvxopt_matrix(np.zeros(1))\n",
    "    \n",
    "    cvxopt_solvers.options['abstol'] = 1e-10\n",
    "    cvxopt_solvers.options['reltol'] = 1e-10\n",
    "    cvxopt_solvers.options['feastol'] = 1e-10\n",
    "\n",
    "    return cvxopt_solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "def train_svm2(kernel):\n",
    "    C = 10\n",
    "\n",
    "    feature = [2, 3]\n",
    "    train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative = get_test_and_train(feature)\n",
    "\n",
    "    train_data = np.squeeze(train_data, axis=(2,))\n",
    "    train_label = np.array(train_label)\n",
    "\n",
    "    n, k = train_data.shape\n",
    "    \n",
    "    y_matrix = y.reshape(1, -1)\n",
    "    H = np.dot(y_matrix.T, y_matrix) * gram_matrix(X, X, kernel)\n",
    "    P = cvxopt_matrix(H)\n",
    "    q = cvxopt_matrix(-np.ones((n, 1)))\n",
    "    G = cvxopt_matrix(np.vstack((-np.eye((n)), np.eye(n))))\n",
    "    h = cvxopt_matrix(np.vstack((np.zeros((n,1)), np.ones((n,1)) * C)))\n",
    "    A = cvxopt_matrix(y_matrix)\n",
    "    b = cvxopt_matrix(np.zeros(1))\n",
    "    \n",
    "    cvxopt_solvers.options['abstol'] = 1e-10\n",
    "    cvxopt_solvers.options['reltol'] = 1e-10\n",
    "    cvxopt_solvers.options['feastol'] = 1e-10\n",
    "\n",
    "    return cvxopt_solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "def train_svm3(kernel):\n",
    "    C = 100\n",
    "\n",
    "    feature = [2, 3]\n",
    "    train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative = get_train_and_test(feature)\n",
    "\n",
    "    train_data = np.squeeze(train_data, axis=(2,))\n",
    "    train_label = np.array(train_label)\n",
    "\n",
    "    n, k = train_data.shape\n",
    "    \n",
    "    y_matrix = y.reshape(1, -1)\n",
    "    H = np.dot(y_matrix.T, y_matrix) * gram_matrix(X, X, kernel)\n",
    "    P = cvxopt_matrix(H)\n",
    "    q = cvxopt_matrix(-np.ones((n, 1)))\n",
    "    G = cvxopt_matrix(np.vstack((-np.eye((n)), np.eye(n))))\n",
    "    h = cvxopt_matrix(np.vstack((np.zeros((n,1)), np.ones((n,1)) * C)))\n",
    "    A = cvxopt_matrix(y_matrix)\n",
    "    b = cvxopt_matrix(np.zeros(1))\n",
    "    \n",
    "    cvxopt_solvers.options['abstol'] = 1e-10\n",
    "    cvxopt_solvers.options['reltol'] = 1e-10\n",
    "    cvxopt_solvers.options['feastol'] = 1e-10\n",
    "\n",
    "    return cvxopt_solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "def train_svm4(kernel):\n",
    "    C = 100\n",
    "\n",
    "    feature = [2, 3]\n",
    "    train_data, test_data, train_label, test_label, train_label_plot, test_label_plot, train_data_positive, train_data_negative, test_data_positive, test_data_negative = get_test_and_train(feature)\n",
    "\n",
    "    train_data = np.squeeze(train_data, axis=(2,))\n",
    "    train_label = np.array(train_label)\n",
    "\n",
    "    n, k = train_data.shape\n",
    "    \n",
    "    y_matrix = y.reshape(1, -1)\n",
    "    H = np.dot(y_matrix.T, y_matrix) * gram_matrix(X, X, kernel)\n",
    "    P = cvxopt_matrix(H)\n",
    "    q = cvxopt_matrix(-np.ones((n, 1)))\n",
    "    G = cvxopt_matrix(np.vstack((-np.eye((n)), np.eye(n))))\n",
    "    h = cvxopt_matrix(np.vstack((np.zeros((n,1)), np.ones((n,1)) * C)))\n",
    "    A = cvxopt_matrix(y_matrix)\n",
    "    b = cvxopt_matrix(np.zeros(1))\n",
    "    \n",
    "    cvxopt_solvers.options['abstol'] = 1e-10\n",
    "    cvxopt_solvers.options['reltol'] = 1e-10\n",
    "    cvxopt_solvers.options['feastol'] = 1e-10\n",
    "\n",
    "    return cvxopt_solvers.qp(P, q, G, h, A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pcost       dcost       gap    pres   dres\n 0: -2.3310e+01 -2.9472e+03  6e+03  6e-01  2e-13\n 1:  3.2470e+01 -7.2125e+02  1e+03  5e-02  2e-13\n 2: -2.1288e+01 -1.6603e+02  2e+02  6e-03  1e-13\n 3: -4.9203e+01 -9.4768e+01  5e+01  2e-03  2e-13\n 4: -5.8984e+01 -7.2923e+01  1e+01  2e-04  2e-13\n 5: -6.2339e+01 -7.0672e+01  8e+00  1e-04  2e-13\n 6: -6.5178e+01 -6.6910e+01  2e+00  2e-05  2e-13\n 7: -6.5868e+01 -6.5934e+01  7e-02  3e-08  2e-13\n 8: -6.5900e+01 -6.5900e+01  7e-04  3e-10  2e-13\n 9: -6.5900e+01 -6.5900e+01  7e-06  3e-12  1e-13\n10: -6.5900e+01 -6.5900e+01  7e-08  3e-14  2e-13\n11: -6.5900e+01 -6.5900e+01  7e-10  1e-14  2e-13\nOptimal solution found.\n{'x': <50x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <100x1 matrix, tc='d'>, 'z': <100x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 6.722454823557572e-10, 'relative gap': 1.0200993662505066e-11, 'primal objective': -65.8999999996739, 'dual objective': -65.9000000003458, 'primal infeasibility': 1.0658141036401503e-14, 'dual infeasibility': 2.1484228919275765e-13, 'primal slack': 1.3384876599277617e-12, 'dual slack': 5.898723926692683e-13, 'iterations': 11}\n"
    }
   ],
   "source": [
    "X, y = generate_data1(DATASET_LINEARLY_SEPARABLE)\n",
    "# X = parameters['X']\n",
    "svm_parameters = train_svm1(KERNEL_LINEAR)\n",
    "print(svm_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Alphas: [ 9.00006523 10.         10.          8.99993477  8.         10.\n 10.         10.        ]\nw and b [-1.6 -4.2] 14.74250000013928\n"
    }
   ],
   "source": [
    "def get_parameters(alphas):\n",
    "    threshold = 1e-5 # Values greater than zero (some floating point tolerance)\n",
    "    S = (alphas > threshold).reshape(-1, )\n",
    "    w = np.dot(X.T, alphas * y)\n",
    "    b = y[S] - np.dot(X[S], w) # b calculation\n",
    "    b = np.mean(b)\n",
    "    return w, b, S\n",
    "\n",
    "alphas = np.array(svm_parameters['x'])[:, 0]\n",
    "w, b, S = get_parameters(alphas)\n",
    "\n",
    "print('Alphas:', alphas[S][0:50])\n",
    "print('w and b', w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.0\n0.0\n9.0001\n0.0\n0.0\n0.0\n10.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n10.0\n0.0\n8.9999\n0.0\n0.0\n0.0\n8.0\n0.0\n0.0\n0.0\n0.0\n10.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n10.0\n0.0\n0.0\n0.0\n10.0\n0.0\n"
    }
   ],
   "source": [
    "# alphas\n",
    "for i in range(len(alphas)):\n",
    "    print('{}'.format(round(alphas[i], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pcost       dcost       gap    pres   dres\n 0: -2.6633e+01 -3.1443e+03  7e+03  6e-01  2e-13\n 1:  4.5308e+01 -6.8677e+02  8e+02  2e-02  2e-13\n 2: -2.4238e+01 -1.3871e+02  1e+02  2e-03  2e-13\n 3: -4.7890e+01 -7.9039e+01  3e+01  4e-04  2e-13\n 4: -5.4621e+01 -7.4160e+01  2e+01  2e-04  2e-13\n 5: -6.0786e+01 -6.6426e+01  6e+00  2e-05  3e-13\n 6: -6.2727e+01 -6.3719e+01  1e+00  4e-06  2e-13\n 7: -6.3102e+01 -6.3127e+01  2e-02  4e-08  3e-13\n 8: -6.3111e+01 -6.3111e+01  4e-04  4e-10  3e-13\n 9: -6.3111e+01 -6.3111e+01  4e-06  4e-12  3e-13\n10: -6.3111e+01 -6.3111e+01  4e-08  4e-14  3e-13\n11: -6.3111e+01 -6.3111e+01  4e-10  7e-15  3e-13\nOptimal solution found.\n{'x': <50x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <100x1 matrix, tc='d'>, 'z': <100x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 3.5834624662963347e-10, 'relative gap': 5.6780215135083095e-12, 'primal objective': -63.111111110993335, 'dual objective': -63.11111111135118, 'primal infeasibility': 7.105427357601002e-15, 'dual infeasibility': 3.195446601385024e-13, 'primal slack': 3.1903625292020255e-13, 'dual slack': 1.681634576510176e-13, 'iterations': 11}\n"
    }
   ],
   "source": [
    "X, y = generate_data2(DATASET_LINEARLY_SEPARABLE)\n",
    "# X = parameters['X']\n",
    "svm_parameters = train_svm2(KERNEL_LINEAR)\n",
    "print(svm_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Alphas: [10.         10.          8.77777778 10.         10.          8.55555555\n 10.          0.22222222 10.        ]\nw and b [-2.66666667 -4.66666667] 20.696296296583967\n"
    }
   ],
   "source": [
    "def get_parameters(alphas):\n",
    "    threshold = 1e-5 # Values greater than zero (some floating point tolerance)\n",
    "    S = (alphas > threshold).reshape(-1, )\n",
    "    w = np.dot(X.T, alphas * y)\n",
    "    b = y[S] - np.dot(X[S], w) # b calculation\n",
    "    b = np.mean(b)\n",
    "    return w, b, S\n",
    "\n",
    "alphas = np.array(svm_parameters['x'])[:, 0]\n",
    "w, b, S = get_parameters(alphas)\n",
    "\n",
    "print('Alphas:', alphas[S][0:50])\n",
    "print('w and b', w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.0\n0.0\n10.0\n0.0\n0.0\n0.0\n0.0\n0.0\n10.0\n0.0\n8.7778\n10.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n10.0\n8.5556\n0.0\n0.0\n0.0\n0.0\n0.0\n10.0\n0.2222\n0.0\n0.0\n0.0\n10.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n"
    }
   ],
   "source": [
    "# alphas\n",
    "for i in range(len(alphas)):\n",
    "    print('{}'.format(round(alphas[i], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pcost       dcost       gap    pres   dres\n 0:  5.0361e+03 -2.2918e+05  4e+05  4e-01  2e-12\n 1:  7.5074e+03 -4.2773e+04  6e+04  3e-02  2e-12\n 2:  1.7487e+03 -7.4395e+03  1e+04  3e-03  1e-12\n 3: -1.5499e+02 -1.4054e+03  1e+03  5e-05  1e-12\n 4: -3.5559e+02 -1.0313e+03  7e+02  2e-05  9e-13\n 5: -4.4018e+02 -6.3139e+02  2e+02  6e-06  1e-12\n 6: -5.2379e+02 -6.5827e+02  1e+02  2e-06  1e-12\n 7: -5.1956e+02 -6.0815e+02  9e+01  7e-14  1e-12\n 8: -5.5485e+02 -5.5807e+02  3e+00  3e-14  1e-12\n 9: -5.5553e+02 -5.5563e+02  1e-01  7e-14  2e-12\n10: -5.5555e+02 -5.5556e+02  5e-03  4e-14  2e-12\n11: -5.5556e+02 -5.5556e+02  5e-04  9e-14  2e-12\n12: -5.5556e+02 -5.5556e+02  7e-05  2e-13  2e-12\n13: -5.5556e+02 -5.5556e+02  1e-05  3e-14  2e-12\n14: -5.5556e+02 -5.5556e+02  1e-06  9e-14  2e-12\n15: -5.5556e+02 -5.5556e+02  2e-07  3e-14  1e-12\n16: -5.5556e+02 -5.5556e+02  3e-08  1e-14  2e-12\nOptimal solution found.\n{'x': <50x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <100x1 matrix, tc='d'>, 'z': <100x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 3.155728531508937e-08, 'relative gap': 5.680311356873456e-11, 'primal objective': -555.5555555401643, 'dual objective': -555.5555555717217, 'primal infeasibility': 1.4210854715202004e-14, 'dual infeasibility': 2.0069860176708096e-12, 'primal slack': 1.3250003203569848e-11, 'dual slack': 6.183765758009109e-13, 'iterations': 16}\nAlphas: [4.20885758e-05 6.05290091e+01 5.70868194e-05 1.00000000e+02\n 2.36009640e-05 4.20885754e-05 4.20885754e-05 1.00000000e+02\n 2.83596728e+01 2.79886205e-05 1.00000000e+02 1.30358438e-05\n 2.11468110e-05 3.33936022e-05 1.00000000e+02 8.88887933e+01]\nw and b [-1.61064462e-04 -6.66666667e+00] 11.000797269068622\n0.0\n0.0\n60.529\n0.0\n0.0001\n0.0\n100.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n100.0\n0.0\n28.3597\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n100.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n100.0\n0.0\n0.0\n0.0\n88.8888\n0.0\n"
    }
   ],
   "source": [
    "X, y = generate_data1(DATASET_LINEARLY_SEPARABLE)\n",
    "# X = parameters['X']\n",
    "svm_parameters = train_svm3(KERNEL_LINEAR)\n",
    "print(svm_parameters)\n",
    "\n",
    "def get_parameters(alphas):\n",
    "    threshold = 1e-5 # Values greater than zero (some floating point tolerance)\n",
    "    S = (alphas > threshold).reshape(-1, )\n",
    "    w = np.dot(X.T, alphas * y)\n",
    "    b = y[S] - np.dot(X[S], w) # b calculation\n",
    "    b = np.mean(b)\n",
    "    return w, b, S\n",
    "\n",
    "alphas = np.array(svm_parameters['x'])[:, 0]\n",
    "w, b, S = get_parameters(alphas)\n",
    "\n",
    "print('Alphas:', alphas[S][0:50])\n",
    "print('w and b', w, b)\n",
    "\n",
    "# alphas\n",
    "for i in range(len(alphas)):\n",
    "    print('{}'.format(round(alphas[i], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pcost       dcost       gap    pres   dres\n 0:  4.4172e+03 -2.4733e+05  5e+05  5e-01  2e-12\n 1:  8.5358e+03 -3.3820e+04  4e+04  2e-03  2e-12\n 2:  1.1755e+03 -4.1302e+03  5e+03  1e-04  2e-12\n 3: -2.2616e+02 -1.3069e+03  1e+03  3e-14  1e-12\n 4: -3.8397e+02 -6.6448e+02  3e+02  1e-14  1e-12\n 5: -4.3299e+02 -5.1997e+02  9e+01  7e-14  1e-12\n 6: -4.5523e+02 -5.1389e+02  6e+01  1e-16  1e-12\n 7: -4.7717e+02 -4.7871e+02  2e+00  7e-14  2e-12\n 8: -4.7755e+02 -4.7756e+02  2e-02  1e-13  2e-12\n 9: -4.7755e+02 -4.7755e+02  2e-04  9e-14  2e-12\n10: -4.7755e+02 -4.7755e+02  2e-06  4e-14  2e-12\n11: -4.7755e+02 -4.7755e+02  2e-08  1e-13  2e-12\nOptimal solution found.\n{'x': <50x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <100x1 matrix, tc='d'>, 'z': <100x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 1.639873344479713e-08, 'relative gap': 3.433922815392128e-11, 'primal objective': -477.5510204041822, 'dual objective': -477.55102042058394, 'primal infeasibility': 1.2789769243681803e-13, 'dual infeasibility': 1.7297011428851011e-12, 'primal slack': 1.0687863382032083e-11, 'dual slack': 1.641476398287691e-12, 'iterations': 11}\nAlphas: [100.         100.           8.74533784  40.234254    64.40200976\n 100.          20.26264513  64.31493695]\nw and b [-2.85714286 -5.71428571] 23.35714285776249\n0.0\n0.0\n100.0\n0.0\n0.0\n0.0\n0.0\n0.0\n100.0\n0.0\n8.7453\n40.2343\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n64.402\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n100.0\n20.2626\n0.0\n0.0\n0.0\n64.3149\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n"
    }
   ],
   "source": [
    "X, y = generate_data2(DATASET_LINEARLY_SEPARABLE)\n",
    "# X = parameters['X']\n",
    "svm_parameters = train_svm4(KERNEL_LINEAR)\n",
    "print(svm_parameters)\n",
    "\n",
    "def get_parameters(alphas):\n",
    "    threshold = 1e-5 # Values greater than zero (some floating point tolerance)\n",
    "    S = (alphas > threshold).reshape(-1, )\n",
    "    w = np.dot(X.T, alphas * y)\n",
    "    b = y[S] - np.dot(X[S], w) # b calculation\n",
    "    b = np.mean(b)\n",
    "    return w, b, S\n",
    "\n",
    "alphas = np.array(svm_parameters['x'])[:, 0]\n",
    "w, b, S = get_parameters(alphas)\n",
    "\n",
    "print('Alphas:', alphas[S][0:50])\n",
    "print('w and b', w, b)\n",
    "\n",
    "# alphas\n",
    "for i in range(len(alphas)):\n",
    "    print('{}'.format(round(alphas[i], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pcost       dcost       gap    pres   dres\n 0:  1.7770e+02 -1.4416e+03  2e+03  4e-15  2e-15\n 1:  2.2010e+01 -1.5362e+02  2e+02  2e-15  1e-15\n 2: -1.8929e+01 -3.9571e+01  2e+01  4e-16  4e-16\n 3: -2.1360e+01 -2.2532e+01  1e+00  4e-15  2e-16\n 4: -2.1377e+01 -2.1392e+01  1e-02  7e-16  1e-16\n 5: -2.1377e+01 -2.1377e+01  1e-04  2e-15  1e-16\n 6: -2.1377e+01 -2.1377e+01  1e-06  4e-15  1e-16\n 7: -2.1377e+01 -2.1377e+01  1e-08  2e-16  1e-16\n 8: -2.1377e+01 -2.1377e+01  1e-10  9e-16  1e-16\nOptimal solution found.\n{'x': <50x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <100x1 matrix, tc='d'>, 'z': <100x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 1.4694045510154807e-10, 'relative gap': 6.873688062938697e-12, 'primal objective': -21.377236464048508, 'dual objective': -21.377236464195448, 'primal infeasibility': 8.881784197001252e-16, 'dual infeasibility': 1.0855906073093382e-16, 'primal slack': 0.321302058731487, 'dual slack': 1.0470498258845193e-14, 'iterations': 8}\nAlphas: [0.53765599 0.32130206 0.62692919 0.54530086 0.94009743 0.96323499\n 1.09293103 1.11025489 0.94014653 1.09065225 1.11025489 1.11052977\n 0.95785184 0.53765576 1.11062734 1.0552137  0.32130206 0.98094657\n 0.32130206 1.09298961 1.25389831 0.5453007  0.62692841 1.0930035\n 1.09092674 0.78335684 0.78300965 0.8736693  0.78305857 0.84137806\n 0.85738051 0.88978832 0.88937266 0.88910996 0.78335684 0.69196329\n 0.88904291 0.88907946 0.67338289 0.88933228 0.88933218 0.78335682\n 0.87333583 0.88933301 1.05906384 0.8736692  0.79767428 0.87337622\n 1.05873569 0.87307786]\nw and b [-29.46747624 -15.19178498] 172.36504550372823\n0.5377\n0.3213\n0.6269\n0.5453\n0.9401\n0.9632\n1.0929\n1.1103\n0.9401\n1.0907\n----\n1.1103\n1.1105\n0.9579\n0.5377\n1.1106\n1.0552\n0.3213\n0.9809\n0.3213\n1.093\n----\n1.2539\n0.5453\n0.6269\n1.093\n1.0909\n0.7834\n0.783\n0.8737\n0.7831\n0.8414\n----\n0.8574\n0.8898\n0.8894\n0.8891\n0.7834\n0.692\n0.889\n0.8891\n0.6734\n0.8893\n----\n0.8893\n0.7834\n0.8733\n0.8893\n1.0591\n0.8737\n0.7977\n0.8734\n1.0587\n0.8731\n----\n"
    }
   ],
   "source": [
    "X, y = generate_data1(DATASET_LINEARLY_SEPARABLE)\n",
    "# X = parameters['X']\n",
    "svm_parameters = train_svm1(KERNEL_RBF)\n",
    "print(svm_parameters)\n",
    "\n",
    "def get_parameters(alphas):\n",
    "    threshold = 1e-5 # Values greater than zero (some floating point tolerance)\n",
    "    S = (alphas > threshold).reshape(-1, )\n",
    "    w = np.dot(X.T, alphas * y)\n",
    "    b = y[S] - np.dot(X[S], w) # b calculation\n",
    "    b = np.mean(b)\n",
    "    return w, b, S\n",
    "\n",
    "alphas = np.array(svm_parameters['x'])[:, 0]\n",
    "w, b, S = get_parameters(alphas)\n",
    "\n",
    "print('Alphas:', alphas[S][0:50])\n",
    "print('w and b', w, b)\n",
    "\n",
    "# alphas\n",
    "for i in range(len(alphas)):\n",
    "    print('{}'.format(round(alphas[i], 4)))\n",
    "    if((i+1)%10==0):\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pcost       dcost       gap    pres   dres\n 0:  1.8277e+02 -1.3193e+03  2e+03  2e-14  2e-15\n 1:  2.0491e+01 -1.4269e+02  2e+02  2e-14  1e-15\n 2: -1.8414e+01 -3.7875e+01  2e+01  7e-15  5e-16\n 3: -2.0692e+01 -2.1783e+01  1e+00  1e-15  2e-16\n 4: -2.0710e+01 -2.0724e+01  1e-02  9e-16  2e-16\n 5: -2.0710e+01 -2.0710e+01  1e-04  9e-16  2e-16\n 6: -2.0710e+01 -2.0710e+01  1e-06  3e-15  1e-16\n 7: -2.0710e+01 -2.0710e+01  1e-08  3e-15  1e-16\n 8: -2.0710e+01 -2.0710e+01  1e-10  9e-16  1e-16\nOptimal solution found.\n{'x': <50x1 matrix, tc='d'>, 'y': <1x1 matrix, tc='d'>, 's': <100x1 matrix, tc='d'>, 'z': <100x1 matrix, tc='d'>, 'status': 'optimal', 'gap': 1.418942531078335e-10, 'relative gap': 6.8514308634677425e-12, 'primal objective': -20.71016345861746, 'dual objective': -20.710163458759354, 'primal infeasibility': 8.881784197001252e-16, 'dual infeasibility': 1.1118780802721762e-16, 'primal slack': 0.3535428924892867, 'dual slack': 9.306676991717254e-15, 'iterations': 8}\nAlphas: [0.92828708 1.03463325 1.0633042  0.44565792 1.05287647 1.01790441\n 1.03457998 0.91107029 1.18416876 0.44565793 0.9328159  1.01564172\n 0.68970643 0.40761223 0.81742782 0.9446903  1.01791745 0.80432929\n 1.05322365 0.35354289 0.92740637 0.35354289 0.81297717 1.05357685\n 0.40761219 0.92940048 0.41652456 0.83780839 0.83333824 0.94642294\n 0.92940058 0.94642315 0.83324553 1.10673123 0.94642304 0.94610577\n 0.46453903 0.94642314 0.41652456 0.94574603 0.46453897 0.83365048\n 0.70244884 0.94610566 0.92940638 0.83328344 0.82061263 0.93343829\n 0.94574623 0.85587587]\nw and b [-26.91229894 -14.37928514] 153.98873243069602\n0.9283\n1.0346\n1.0633\n0.4457\n1.0529\n1.0179\n1.0346\n0.9111\n1.1842\n0.4457\n----\n0.9328\n1.0156\n0.6897\n0.4076\n0.8174\n0.9447\n1.0179\n0.8043\n1.0532\n0.3535\n----\n0.9274\n0.3535\n0.813\n1.0536\n0.4076\n0.9294\n0.4165\n0.8378\n0.8333\n0.9464\n----\n0.9294\n0.9464\n0.8332\n1.1067\n0.9464\n0.9461\n0.4645\n0.9464\n0.4165\n0.9457\n----\n0.4645\n0.8337\n0.7024\n0.9461\n0.9294\n0.8333\n0.8206\n0.9334\n0.9457\n0.8559\n----\n"
    }
   ],
   "source": [
    "X, y = generate_data2(DATASET_LINEARLY_SEPARABLE)\n",
    "# X = parameters['X']\n",
    "svm_parameters = train_svm2(KERNEL_RBF)\n",
    "print(svm_parameters)\n",
    "\n",
    "def get_parameters(alphas):\n",
    "    threshold = 1e-5 # Values greater than zero (some floating point tolerance)\n",
    "    S = (alphas > threshold).reshape(-1, )\n",
    "    w = np.dot(X.T, alphas * y)\n",
    "    b = y[S] - np.dot(X[S], w) # b calculation\n",
    "    b = np.mean(b)\n",
    "    return w, b, S\n",
    "\n",
    "alphas = np.array(svm_parameters['x'])[:, 0]\n",
    "w, b, S = get_parameters(alphas)\n",
    "\n",
    "print('Alphas:', alphas[S][0:50])\n",
    "print('w and b', w, b)\n",
    "\n",
    "# alphas\n",
    "for i in range(len(alphas)):\n",
    "    print('{}'.format(round(alphas[i], 4)))\n",
    "    if((i+1)%10==0):\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36564bit3834bea6c78e49f6ab837f3a72fca529",
   "display_name": "Python 3.6.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}