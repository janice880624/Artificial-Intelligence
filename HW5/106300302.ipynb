{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(data, label):\n",
    "    x_train = np.concatenate((data[0:25, :], data[50:75, :], data[100:125, :]), axis=0)\n",
    "    x_test = np.concatenate((data[25:50, :], data[75:100, :], data[125:150, :]), axis=0)\n",
    "\n",
    "    y_train = np.concatenate((label[0:25], label[50:75], label[100:125]), axis=0)\n",
    "    y_test = np.concatenate((label[25:50], label[75:100], label[125:150]), axis=0)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_test.shape)\n",
    "# (75, 4)\n",
    "# (75,)\n",
    "# (75, 4)\n",
    "# (75,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = np.loadtxt('iris.txt')\n",
    "x_train, y_train, x_test, y_test = data(iris_data[:, :4], iris_data[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_class_scatter(data):\n",
    "    within_class_scatter = 0\n",
    "    for class_data in [data[:, :25], data[:, 25:50], data[:, 50:75]]:\n",
    "        prior_probability = class_data.shape[1] / data.shape[1]\n",
    "        data_count = class_data.shape[1]\n",
    "        mean_vector = np.mean(class_data, axis=1)\n",
    "\n",
    "        data_scatter = 0\n",
    "        for data_index in range(data_count):\n",
    "            data_minus_mean_vector = np.expand_dims((class_data[:, data_index] - mean_vector), axis=1)\n",
    "            data_scatter += data_minus_mean_vector.dot(data_minus_mean_vector.T)\n",
    "            \n",
    "        within_class_scatter += data_scatter * prior_probability / data_count\n",
    "\n",
    "    return within_class_scatter\n",
    "\n",
    "# within_class_scatter = within_class_scatter(x_train.T)\n",
    "# within_class_scatter\n",
    "# array([[0.315232  , 0.11170667, 0.205712  , 0.04266133],\n",
    "#        [0.11170667, 0.12501333, 0.06198933, 0.041328  ],\n",
    "#        [0.205712  , 0.06198933, 0.209152  , 0.044144  ],\n",
    "#        [0.04266133, 0.041328  , 0.044144  , 0.03794133]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def between_class_scatter(data):\n",
    "    between_class_scatter = 0\n",
    "    mean_vector = np.expand_dims(data.mean(axis=1), axis=1)\n",
    "    for class_data in [data[:, :25], data[:, 25:50], data[:, 50:75]]:\n",
    "        prior_probability = class_data.shape[1] / data.shape[1]\n",
    "        class_mean_vector = np.expand_dims(class_data.mean(axis=1), axis=1)\n",
    "        between_class_scatter += (class_mean_vector - mean_vector).dot((class_mean_vector - mean_vector).T)\n",
    "\n",
    "    between_class_scatter = prior_probability * between_class_scatter\n",
    "        \n",
    "    return  between_class_scatter\n",
    "\n",
    "# between_class_scatter = get_between_class_scatter(x_train.T)\n",
    "# between_class_scatter\n",
    "# array([[ 0.409184  , -0.16238933,  1.114     ,  0.472608  ],\n",
    "#        [-0.16238933,  0.09149156, -0.45703467, -0.184064  ],\n",
    "#        [ 1.114     , -0.45703467,  3.04109867,  1.28474133],\n",
    "#        [ 0.472608  , -0.184064  ,  1.28474133,  0.54631467]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fisher_score(within_class_scatter, between_class_scatter):\n",
    "    performance_index = between_class_scatter / within_class_scatter\n",
    "    fisher_score = [performance_index[index, index] for index in range(performance_index.shape[0])]\n",
    "        \n",
    "    return fisher_score\n",
    "\n",
    "# fisher_score\n",
    "# [1.2980408080397958,\n",
    "#  0.7318543799772459,\n",
    "#  14.540136678906569,\n",
    "#  14.398931684003369]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(x_train, y_train, x_test, y_test):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_model.fit(x_train, y_train)\n",
    "\n",
    "    return knn_model.score(x_test, y_test)\n",
    "\n",
    "\n",
    "def get_model_accuracy(x_train, y_train, x_test, y_test):\n",
    "    accuracy_1 = knn_model(x_train, y_train, x_test, y_test)\n",
    "    \n",
    "    x_train, x_test = x_test, x_train\n",
    "    y_train, y_test = y_test, y_train\n",
    "    accuracy_2 = knn_model(x_train, y_train, x_test, y_test)\n",
    "\n",
    "    accuracy = (accuracy_1 + accuracy_2) / 2\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_class_scatter = within_class_scatter(x_train.T)\n",
    "between_class_scatter = between_class_scatter(x_train.T)\n",
    "fisher_score = fisher_score(within_class_scatter, between_class_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "When use top-1 features, accuracy is: 0.9199999999999999\nWhen use top-2 features, accuracy is: 0.9533333333333334\nWhen use top-3 features, accuracy is: 0.9533333333333334\nWhen use top-4 features, accuracy is: 0.94\n"
    }
   ],
   "source": [
    "feature_rank = [sorted(fisher_score).index(x) for x in fisher_score][::-1]\n",
    "for rank_index in range(len(feature_rank)):\n",
    "    rank_index += 1\n",
    "    selected_features = feature_rank[:rank_index]\n",
    "    accuracy = get_model_accuracy(x_train[:, selected_features], y_train, x_test[:, selected_features], y_test)\n",
    "    print(\"When use top-{} features, accuracy is: {}\".format(rank_index, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitf6edfb78403b4bd6be10b24de1d94837",
   "display_name": "Python 3.7.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}